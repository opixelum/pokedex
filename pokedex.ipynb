{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "X5itETwybXwO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f28c12a-ef3f-49ef-ef5d-17fe29138991"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/opixelum/pokedex/blob/main/dataset.zip?raw=true\n",
            "78296543/78296543 [==============================] - 1s 0us/step\n",
            "1139 images downloaded.\n"
          ]
        }
      ],
      "source": [
        "# Import dataset\n",
        "import os\n",
        "import pathlib\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "# Get dataset from GitHub\n",
        "data_dir = tf.keras.utils.get_file(\n",
        "    \"dataset.zip\",\n",
        "    \"https://github.com/opixelum/pokedex/blob/main/dataset.zip?raw=true\",\n",
        "    extract=False\n",
        ")\n",
        "\n",
        "# Extract zip file\n",
        "with zipfile.ZipFile(data_dir, 'r') as zip_ref:\n",
        "  zip_ref.extractall('/content/datasets')\n",
        "\n",
        "# Get number of images\n",
        "data_dir = pathlib.Path('/content/datasets/dataset')\n",
        "image_count = len(list(data_dir.glob('*/*')))\n",
        "print(image_count, \"images downloaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare dataset for training & validation\n",
        "batch_size = 3\n",
        "image_height = 200\n",
        "image_width = 200\n",
        "\n",
        "training_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=42,\n",
        "    image_size=(image_height, image_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "validation_data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=42,\n",
        "    image_size=(image_height, image_width),\n",
        "    batch_size=batch_size\n",
        ")"
      ],
      "metadata": {
        "id": "Kz7BaSqakjzG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fc2bc5f-bfe5-4cfa-9d35-e060cec23979"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1113 files belonging to 2 classes.\n",
            "Using 891 files for training.\n",
            "Found 1113 files belonging to 2 classes.\n",
            "Using 222 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iETojt-6qACe"
      },
      "source": [
        "# Define convolutional neural network\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    layers.experimental.preprocessing.Rescaling(1./255),\n",
        "    layers.Conv2D(128, 4, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64, 4, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(32, 4, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(16, 4, activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "logdir=\"logs\"\n",
        "tensorboard_callback = keras.callbacks.TensorBoard(\n",
        "    log_dir=logdir,\n",
        "    histogram_freq=1,\n",
        "    write_images=logdir,\n",
        "    embeddings_data=training_data\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    training_data,\n",
        "    validation_data=validation_data,\n",
        "    epochs=20,\n",
        "    callbacks=[tensorboard_callback]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        },
        "id": "KP23xwDCoBac",
        "outputId": "30decb10-71ab-48aa-d278-aa5673a8acbf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`embeddings_data` is not supported in TensorFlow 2.0. Instead, all `Embedding` variables will be visualized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            " 96/297 [========>.....................] - ETA: 4s - loss: 0.6339 - accuracy: 0.6840"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node decode_image/DecodeImage defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Unknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]]\n\t [[IteratorGetNext]]\n  (1) CANCELLED:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1569]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-83ad83484846>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node decode_image/DecodeImage defined at (most recent call last):\n<stack traces unavailable>\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Unknown image file format. One of JPEG, PNG, GIF, BMP required.\n\t [[{{node decode_image/DecodeImage}}]]\n\t [[IteratorGetNext]]\n  (1) CANCELLED:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_1569]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference\n",
        "import cv2\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "file_to_predict = files.upload()\n",
        "\n",
        "for file_ in file_to_predict:\n",
        "    image_to_predict = cv2.imread(file_,cv2.IMREAD_COLOR)\n",
        "    plt.imshow(cv2.cvtColor(image_to_predict, cv2.COLOR_BGR2RGB))\n",
        "    plt.show()\n",
        "    img_to_predict = np.expand_dims(cv2.resize(image_to_predict,(200,200)), axis=0)\n",
        "\n",
        "    predict = model.predict(img_to_predict)\n",
        "    res = np.argmax(predict, axis=1)\n",
        "\n",
        "    if res == 0:\n",
        "      print(\"It's an Lucario!\")\n",
        "    elif res == 1:\n",
        "      print(\"It's a Entei!\")"
      ],
      "metadata": {
        "id": "HrNZTyuGqFLt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}